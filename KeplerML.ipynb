{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold='nan')\n",
    "from scipy import stats\n",
    "from multiprocessing import Pool,cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put the appropriate file here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lcs = np.load(\"data/KeplerSampleWErr.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:68: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:2079: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:68: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:2079: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:2079: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:2087: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (dot(X, X_T.conj())/fact).squeeze()\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:2079: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:2087: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (dot(X, X_T.conj())/fact).squeeze()\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:2087: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (dot(X, X_T.conj())/fact).squeeze()\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:68: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:2087: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (dot(X, X_T.conj())/fact).squeeze()\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:68: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:116: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:116: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:116: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:116: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:263: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:263: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:263: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:265: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:265: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:262: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:262: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:263: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:265: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:258: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:265: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:258: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:265: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:263: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:262: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/Dan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:258: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "def calc_outliers_pts(t, nf):\n",
    "    # Is t really a necessary input? The answer is no, but eh\n",
    "    posthreshold = np.mean(nf)+4*np.std(nf)\n",
    "    negthreshold = np.mean(nf)-4*np.std(nf)\n",
    "    \n",
    "    numposoutliers,numnegoutliers,numout1s=0,0,0\n",
    "    for j in range(len(nf)):\n",
    "        # First checks if nf[j] is outside of 1 sigma\n",
    "        if abs(np.mean(nf)-nf[j])>np.std(nf):\n",
    "            numout1s += 1\n",
    "            if nf[j]>posthreshold:\n",
    "                numposoutliers += 1\n",
    "            elif nf[j]<negthreshold:\n",
    "                numnegoutliers += 1\n",
    "    numoutliers=numposoutliers+numnegoutliers\n",
    "    \n",
    "    return numoutliers, numposoutliers, numnegoutliers, numout1s\n",
    "\n",
    "def calc_slopes(t, nf, corrnf):\n",
    "\n",
    "    slope_array = np.zeros(20)\n",
    "\n",
    "    #Delta flux/ Delta time\n",
    "    slopes=[(nf[j+1]-nf[j])/(t[j+1]-t[j]) for j in range (len(nf)-1)]\n",
    "    #corrslopes removes the longterm linear trend (if any) and then looks at the slope\n",
    "    corrslopes=[(corrnf[j+1]-corrnf[j])/(t[j+1]-t[j]) for j in range (len(corrnf)-1)]\n",
    "    meanslope = np.mean(slopes)\n",
    "    # by looking at where the 99th percentile is instead of just the largest number,\n",
    "    # I think it avoids the extremes which might not be relevant (might be unreliable data)\n",
    "    # Is the miniumum slope the most negative one, or the flattest one? Answer: Most negative\n",
    "    maxslope=np.percentile(slopes,99)\n",
    "    minslope=np.percentile(slopes,1)\n",
    "    # Separating positive slopes and negative slopes\n",
    "    # Should both include the 0 slope? I'd guess there wouldn't be a ton, but still...\n",
    "    pslope=[slopes[j] for j in range(len(slopes)) if slopes[j]>=0]\n",
    "    nslope=[slopes[j] for j in range(len(slopes)) if slopes[j]<=0]\n",
    "    # Looking at the average (mean) positive and negative slopes\n",
    "    meanpslope=np.mean(pslope)\n",
    "    meannslope=np.mean(nslope)\n",
    "    # Quantifying the difference in shape.\n",
    "    g_asymm=meanpslope / meannslope\n",
    "    # Won't this be skewed by the fact that both pslope and nslope have all the 0's? Eh\n",
    "    rough_g_asymm=len(pslope) / len(nslope)\n",
    "    # meannslope is inherently negative, so this is the difference btw the 2\n",
    "    diff_asymm=meanpslope + meannslope\n",
    "    skewslope = stats.skew(slopes)\n",
    "    absslopes=[abs(slopes[j]) for j in range(len(slopes))]\n",
    "    meanabsslope=np.mean(absslopes)\n",
    "    varabsslope=np.var(absslopes)\n",
    "    varslope=np.var(slopes)\n",
    "    #secder = Second Derivative\n",
    "    # Reminder for self: the slope is \"located\" halfway between the flux and time points, \n",
    "    # so the delta t in the denominator is accounting for that.\n",
    "    #secder=[(slopes[j]-slopes[j-1])/((t[j+1]-t[j])/2+(t[j]-t[j-1])/2) for j in range(1, len(nf)-1)]\n",
    "    #algebraic simplification:\n",
    "    secder=[2*(slopes[j]-slopes[j-1])/(t[j+1]-t[j-1]) for j in range(1, len(nf)-1)]\n",
    "    meansecder=np.mean(secder)\n",
    "    #abssecder=[abs((slopes[j]-slopes[j-1])/((t[j+1]-t[j])/2+(t[j]-t[j-1])/2)) for j in range (1, len(slopes)-1)]\n",
    "    # simplification:\n",
    "    abssecder=[abs(secder[j]) for j in range(1, len(secder))]\n",
    "    absmeansecder=np.mean(abssecder)\n",
    "\n",
    "    pslopestds=np.std(pslope)\n",
    "    nslopestds=np.std(nslope)\n",
    "    sdstds=np.std(secder)\n",
    "    meanstds=np.mean(secder)\n",
    "    stdratio=pslopestds/nslopestds\n",
    "\n",
    "    pspikes =[slopes[j] for j in range(len(slopes)) if slopes[j]>=meanpslope+3*pslopestds] \n",
    "    nspikes=[slopes[j] for j in range(len(slopes)) if slopes[j]<=meannslope-3*nslopestds]\n",
    "    psdspikes=[secder[j] for j in range(len(secder)) if secder[j]>=4*sdstds] \n",
    "    nsdspikes=[secder[j] for j in range(len(secder)) if secder[j]<=-4*sdstds]\n",
    "\n",
    "    num_pspikes = len(pspikes)\n",
    "    num_nspikes = len(nspikes)\n",
    "    num_psdspikes = len(psdspikes)\n",
    "    num_nsdspikes = len(nsdspikes)\n",
    "    \n",
    "    stdratio = pslopestds / nslopestds\n",
    "    # The ratio of postive slopes with a following postive slope to the total number of points.\n",
    "\n",
    "    pstrend=len([slopes[j] for j in range(len(slopes)-1) if (slopes[j]>0) & (slopes[j+1]>0)])/len(slopes)\n",
    "\n",
    "    slope_array = [meanslope, maxslope, minslope, meanpslope, meannslope, g_asymm, rough_g_asymm, diff_asymm, skewslope, varabsslope, varslope, meanabsslope, absmeansecder, num_pspikes, num_nspikes, num_psdspikes, num_nsdspikes, stdratio, pstrend]\n",
    "\n",
    "    return slopes, corrslopes, secder, slope_array\n",
    "\n",
    "def calc_maxmin_periodics(t, nf, err):\n",
    "#look up this heapq.nlargest crap\n",
    "    #This looks up the local maximums. Adds a peak if it's the largest within 10 points on either side.\n",
    "\n",
    "    naivemax,nmax_times = [],[]\n",
    "    naivemins = []\n",
    "    for j in range(len(nf)):\n",
    "        if nf[j] == max(nf[max(j-10,0):min(j+10,len(nf)-1)]):\n",
    "            naivemax.append(nf[j])\n",
    "            nmax_times.append(t[j])\n",
    "        elif nf[j] == min(nf[max(j-10,0):min(j+10,len(nf)-1)]):\n",
    "            naivemins.append(nf[j])\n",
    "    len_nmax=len(naivemax) #F33\n",
    "    len_nmin=len(naivemins) #F34\n",
    "    \n",
    "\n",
    "    #wtf is this?\n",
    "    #D: shifts everything to the left for some reason.\n",
    "    #autopdcmax = [naivemax[j+1] for j in range(len(naivemax)-1)] = naivemax[1:]\n",
    "    \n",
    "    #naivemax[:-1:] is naivemax without the last value and autopdcmax is naivemax without the first value. why do this?a\n",
    "    #np.corrcoef(array) returns a correlation coefficient matrix. I.e. a normalized covariance matrix\n",
    "    \"\"\"\n",
    "    It looks like it compares each point to it's next neighbor, hence why they're offset, \n",
    "    then determines if there's a correlation between the two. If the coefficient is closer\n",
    "    to 1, then there's a strong correlation, if 0 then no correlation, if -1 (possible?) then anti-correlated.\n",
    "    \"\"\"\n",
    "    mautocorrcoef = np.corrcoef(naivemax[:-1], naivemax[1:])[0][1] #F35\n",
    "    mautocovs = np.cov(naivemax[:-1],naivemax[1:])[0][1] # Not a feature, not used elsewhere\n",
    "\n",
    "    \"\"\"peak to peak slopes\"\"\"\n",
    "    ppslopes = [abs((naivemax[j+1]-naivemax[j])/(nmax_times[j+1]-nmax_times[j])) for j in range(len(naivemax)-1)]\n",
    "\n",
    "    ptpslopes=np.mean(ppslopes) #F36\n",
    "\n",
    "    maxdiff=[nmax_times[j+1]-nmax_times[j] for j in range(len(naivemax)-1)]\n",
    "\n",
    "    periodicity=np.std(maxdiff)/np.mean(maxdiff) #F37\n",
    "    periodicityr=np.sum(abs(maxdiff-np.mean(maxdiff)))/np.mean(maxdiff) #F38\n",
    "\n",
    "    naiveperiod=np.mean(maxdiff) #F39\n",
    "    # why not maxvars = np.var(naivemax)? Is this not the variance? Seems like it should be...\n",
    "    #maxvars = np.var(naivemax) #F40\n",
    "    maxvars = np.std(naivemax)/np.mean(naivemax) #F40\n",
    "    # I don't understand what this is.\n",
    "    maxvarsr = np.sum(abs(naivemax-np.mean(naivemax)))/np.mean(naivemax) #F41\n",
    "\n",
    "    emin = naivemins[::2] # even indice minimums\n",
    "    omin = naivemins[1::2] # odd indice minimums\n",
    "    meanemin = np.mean(emin)\n",
    "    meanomin = np.mean(omin)\n",
    "    oeratio = meanomin/meanemin #F42\n",
    "\n",
    "    peaktopeak_array = [len_nmax, len_nmin, mautocorrcoef, ptpslopes, periodicity, periodicityr, naiveperiod, maxvars, maxvarsr, oeratio]\n",
    "\n",
    "    return peaktopeak_array, naivemax, naivemins\n",
    "\n",
    "def featureCalculation(lc):\n",
    "    t = lc[0]\n",
    "    nf = lc[1]\n",
    "    err = lc[2]\n",
    "    \n",
    "    # t = time\n",
    "    # err = error\n",
    "    # nf = normalized flux.\n",
    "    \n",
    "    longtermtrend = np.polyfit(t, nf, 1)[0] # Feature 1 (Abbr. F1) overall slope\n",
    "    yoff = np.polyfit(t, nf, 1)[1] # Not a feature? y-intercept of linear fit\n",
    "    meanmedrat = np.mean(nf) / np.median(nf) # F2\n",
    "    skews = stats.skew(nf) # F3\n",
    "    varss = np.var(nf) # F4\n",
    "    coeffvar = np.std(nf)/np.mean(nf) #F5\n",
    "    stds = np.std(nf) #F6\n",
    "\n",
    "    corrnf = nf - longtermtrend*t - yoff #this removes any linear slope to lc so you can look at just troughs - is this a sign err tho?\n",
    "    # D: I don't think there's a sign error\n",
    "\n",
    "    # Features 7 to 10\n",
    "    numoutliers, numposoutliers, numnegoutliers, numout1s = calc_outliers_pts(t, nf)\n",
    "\n",
    "    kurt = stats.kurtosis(nf)\n",
    "\n",
    "    mad = np.median([abs(nf[j]-np.median(nf)) for j in range(len(nf))])\n",
    "\n",
    "    # slopes array contains features 13-30\n",
    "    slopes, corrslopes, secder, slopes_array = calc_slopes(t, nf, corrnf) \n",
    "\n",
    "    maxslope = slopes_array[0]\n",
    "    minslope = slopes_array[1]\n",
    "    meanpslope  = slopes_array[2]\n",
    "    meannslope  = slopes_array[3]\n",
    "    g_asymm = slopes_array[4]\n",
    "    rough_g_asymm  = slopes_array[5]\n",
    "    diff_asymm  = slopes_array[6]\n",
    "    skewslope  = slopes_array[7]\n",
    "    varabsslope  = slopes_array[8]\n",
    "    varslope  = slopes_array[9]\n",
    "    meanabsslope  = slopes_array[10]\n",
    "    absmeansecder = slopes_array[11]\n",
    "    num_pspikes = slopes_array[12]\n",
    "    num_nspikes  = slopes_array[13]\n",
    "    num_psdspikes = slopes_array[14]\n",
    "    num_nsdspikes = slopes_array[15]\n",
    "    stdratio = slopes_array[16]\n",
    "    pstrend = slopes_array[17]\n",
    "\n",
    "    # Checks if the flux crosses the zero line.\n",
    "    zcrossind= [j for j in range(len(nf)-1) if corrnf[j]*corrnf[j+1]<0]\n",
    "    num_zcross = len(zcrossind) #F31\n",
    "\n",
    "    plusminus=[j for j in range(1,len(slopes)) if (slopes[j]<0)&(slopes[j-1]>0)]\n",
    "    num_pm = len(plusminus)\n",
    "\n",
    "    # peak to peak array contains features 33 - 42\n",
    "    peaktopeak_array, naivemax, naivemins = calc_maxmin_periodics(t, nf, err)\n",
    "\n",
    "    len_nmax=peaktopeak_array[0]\n",
    "    len_nmin=peaktopeak_array[1]\n",
    "    mautocorrcoef=peaktopeak_array[2]\n",
    "    ptpslopes=peaktopeak_array[3]\n",
    "    periodicity=peaktopeak_array[4]\n",
    "    periodicityr=peaktopeak_array[5]\n",
    "    naiveperiod=peaktopeak_array[6]\n",
    "    maxvars=peaktopeak_array[7]\n",
    "    maxvarsr=peaktopeak_array[8]\n",
    "    oeratio=peaktopeak_array[9]\n",
    "\n",
    "    # amp here is actually amp_2 in revantese\n",
    "    # 2x the amplitude (peak-to-peak really), the 1st percentile will be negative, so it's really adding magnitudes\n",
    "    amp = np.percentile(nf,99)-np.percentile(nf,1) #F43\n",
    "    normamp = amp / np.mean(nf) #this should prob go, since flux is norm'd #F44\n",
    "\n",
    "    # ratio of points within 10% of middle to total number of points \n",
    "    mbp = len([nf[j] for j in range(len(nf)) if (nf[j] < (np.median(nf) + 0.1*amp)) & (nf[j] > (np.median(nf)-0.1*amp))]) / len(nf) #F45\n",
    "\n",
    "    f595 = np.percentile(nf,95)-np.percentile(nf,5)\n",
    "    f1090 =np.percentile(nf,90)-np.percentile(nf,10)\n",
    "    f1782 =np.percentile(nf, 82)-np.percentile(nf, 17)\n",
    "    f2575 =np.percentile(nf, 75)-np.percentile(nf, 25)\n",
    "    f3267 =np.percentile(nf, 67)-np.percentile(nf, 32)\n",
    "    f4060 =np.percentile(nf, 60)-np.percentile(nf, 40)\n",
    "    mid20 =f4060/f595 #F46\n",
    "    mid35 =f3267/f595 #F47\n",
    "    mid50 =f2575/f595 #F48\n",
    "    mid65 =f1782/f595 #F49\n",
    "    mid80 =f1090/f595 #F50 \n",
    "\n",
    "    percentamp = max([(nf[j]-np.median(nf)) / np.median(nf) for j in range(len(nf))]) #F51\n",
    "    magratio = (max(nf)-np.median(nf)) / amp #F52\n",
    "\n",
    "    #autopdc=[nf[j+1] for j in range(len(nf)-1)] = nf[1:]\n",
    "    autocorrcoef = np.corrcoef(nf[:-1], nf[1:])[0][1] #F54\n",
    "    #autocovs = np.cov(nf[:-1], nf[1:])[0][1] # not used for anything...\n",
    "\n",
    "    #sautopdc=[slopes[j+1] for j in range(len(slopes)-1)] = slopes[1:]\n",
    "\n",
    "    sautocorrcoef = np.corrcoef(slopes[:-1], slopes[1:])[0][1] #F55\n",
    "    #sautocovs = np.cov(slopes[:-1:],slopes[1:])[0][1] # not used for anything...\n",
    "\n",
    "    flatness = [np.mean(slopes[max(0,j-6):min(j-1, len(slopes)-1):1])- np.mean(slopes[max(0,j):min(j+4, len(slopes)-1):1]) for j in range(len(slopes)) if nf[j] in naivemax]\n",
    "\n",
    "    flatmean = np.nansum(flatness)/len(flatness) #F55\n",
    "\n",
    "    # trying flatness w slopes and nf rather than \"corr\" vals, despite orig def in RN's program\n",
    "    tflatness = [-np.mean(slopes[max(0,j-6):min(j-1, len(slopes)-1):1])+ np.mean(slopes[max(0,j):min(j+4, len(slopes)-1):1]) for j in range(len(slopes)) if nf[j] in naivemins] \n",
    "    # tflatness for mins, flatness for maxes\n",
    "    tflatmean = np.nansum(tflatness) / len(tflatness) #F56\n",
    "\n",
    "    roundness=[np.mean(secder[max(0,j-6):min(j-1, len(secder)-1):1]) + np.mean(secder[max(0,j+1):min(j+6, len(secder)-1):1]) for j in range(len(secder)) if nf[j+1] in naivemax]\n",
    "\n",
    "    roundmean = np.nansum(roundness) / len(roundness) #F57\n",
    "\n",
    "    troundness = [np.mean(secder[max(0,j-6):min(j-1, len(secder)-1):1]) + np.mean(secder[max(0,j+1):min(j+6, len(secder)-1):1]) for j in range(len(secder)) if nf[j+1] in naivemins]\n",
    "\n",
    "    troundmean = np.nansum(troundness)/len(troundness) #F58\n",
    "    roundrat = roundmean / troundmean #F59\n",
    "\n",
    "    flatrat = flatmean / tflatmean #F60\n",
    "\n",
    "    ndata = [longtermtrend, meanmedrat, skews, varss, coeffvar, stds, numoutliers, numnegoutliers, numposoutliers, numout1s, kurt, mad, maxslope, minslope, meanpslope, meannslope, g_asymm, rough_g_asymm, diff_asymm, skewslope, varabsslope, varslope, meanabsslope, absmeansecder, num_pspikes, num_nspikes, num_psdspikes, num_nsdspikes,stdratio, pstrend, num_zcross, num_pm, len_nmax, len_nmin, mautocorrcoef, ptpslopes, periodicity, periodicityr, naiveperiod, maxvars, maxvarsr, oeratio, amp, normamp,mbp, mid20, mid35, mid50, mid65, mid80, percentamp, magratio, sautocorrcoef, autocorrcoef, flatmean, tflatmean, roundmean, troundmean, roundrat, flatrat]\n",
    "    return ndata\n",
    "\n",
    "fdata = []\n",
    "numCpus = cpu_count()\n",
    "p = Pool(cpu_count())\n",
    "fdata = p.map(featureCalculation,lcs)\n",
    "p.close()\n",
    "p.join()\n",
    "fdata = np.array(fdata)\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"data/ftData.npy\",fdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
